{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "to be uploaded_code_densnet121_256_features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_xryPpKGneC"
      },
      "source": [
        "# Reading all three csv files\n",
        "import pandas as pd\n",
        "data_grade_train = pd.read_excel('/content/drive/MyDrive/over_sampling_dataset/2. Groundtruths/a. IDRiD_Disease Grading_Training Labels.xlsx')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG4epbcyxITd"
      },
      "source": [
        "data_grade_test = pd.read_csv('/content/drive/MyDrive/over_sampling_dataset/2. Groundtruths/b. IDRiD_Disease Grading_Testing Labels.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0XQ0p0tLVS1"
      },
      "source": [
        "data_grade_train = data_grade_train[['Image name','Retinopathy grade','Risk of macular edema ']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpVrL35axGXO"
      },
      "source": [
        "data_grade_test = data_grade_test[['Image name','Retinopathy grade','Risk of macular edema ']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp4iRjNSLYYW"
      },
      "source": [
        "print(data_grade_train)\n",
        "print(data_grade_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INxLzGlFo7xM"
      },
      "source": [
        "label_train = data_grade_train['Risk of macular edema ']\n",
        "label_test = data_grade_test['Risk of macular edema '] \n",
        "print(label_train)\n",
        "print(label_test)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "label_train_cat = to_categorical(label_train)\n",
        "label_test_cat = to_categorical(label_test)\n",
        "print(\"label_train_cat.shape\",label_train_cat.shape)\n",
        "print(\"label_test_cat.shape\",label_test_cat.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0pix0hCZcfy"
      },
      "source": [
        "image_path_train = data_grade_train['Image name']\n",
        "image_path_train\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from skimage import io\n",
        "image_read_train = []\n",
        "for imagepath in image_path_train:\n",
        "  print(imagepath)\n",
        "  image_path1_train = os.path.join('/content/drive/MyDrive/over_sampling_dataset/1. Original Images/a. Training Set 577',imagepath+'.jpg')\n",
        "  #print(image_path1)\n",
        "  image1_train = cv2.imread(image_path1_train)\n",
        "\n",
        "  #median_train = cv2.medianBlur(image1_train,5)\n",
        "\n",
        "  #Control Limited Adaptive Histogram Equlization (CLAHE)\n",
        "  '''\n",
        "  lab_img = cv2.cvtColor(median_train, cv2.COLOR_BGR2LAB)\n",
        "  l, a, b = cv2.split(lab_img) \n",
        "  clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8,8))\n",
        "  clahe_img = clahe.apply(l)\n",
        "  updated_lab_img = cv2.merge((clahe_img,a,b))\n",
        "  CLAHE_img = cv2.cvtColor(updated_lab_img,cv2.COLOR_LAB2BGR)\n",
        "  '''  \n",
        "  green_channel = image1_train[:,:,1]\n",
        "  # create empty image with same shape as that of src image\n",
        "  green_img = np.zeros(image1_train.shape)\n",
        "  #assign the green channel of src to empty image\n",
        "  green_img[:,:,1] = green_channel\n",
        "  \n",
        "  image2_train = cv2.resize(green_img,(448,448))\n",
        "  image3_train = image2_train.astype('float32')\n",
        "  image4_train = image3_train/255\n",
        "  image_read_train.append(image4_train)\n",
        "image_array_train = np.asarray(image_read_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-za18MvBH6i"
      },
      "source": [
        "image_path_test = data_grade_test['Image name']\n",
        "image_path_test\n",
        "image_read_test = []\n",
        "for imagepath in image_path_test:\n",
        "  print(imagepath)\n",
        "  image_path1_test = os.path.join('/content/drive/MyDrive/over_sampling_dataset/1. Original Images/b. Testing Set 103',imagepath+'.jpg')\n",
        "  #print(image_path1_test)\n",
        "  image1_test = cv2.imread(image_path1_test)\n",
        "  #median_test = cv2.medianBlur(image1_test,5)\n",
        "\n",
        "  #Control Limited Adaptive Histogram Equlization (CLAHE)\n",
        "  '''\n",
        "  lab_img = cv2.cvtColor(median_test, cv2.COLOR_BGR2LAB)\n",
        "  l, a, b = cv2.split(lab_img)\n",
        "  clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8,8))\n",
        "  clahe_img = clahe.apply(l)\n",
        "  updated_lab_img = cv2.merge((clahe_img,a,b))\n",
        "  CLAHE_img = cv2.cvtColor(updated_lab_img,cv2.COLOR_LAB2BGR)\n",
        "  '''\n",
        "  \n",
        "  green_channel = image1_test[:,:,1]\n",
        "\n",
        "  # create empty image with same shape as that of src image\n",
        "  green_img = np.zeros(image1_test.shape)\n",
        "\n",
        "  #assign the green channel of src to empty image\n",
        "  green_img[:,:,1] = green_channel\n",
        "  print(green_img.shape)\n",
        "  image2_test = cv2.resize(green_img,(448,448))\n",
        "  image3_test = image2_test.astype('float32')\n",
        "  image4_test = image3_test/255\n",
        "  print(image4_test.shape)\n",
        "  image_read_test.append(image4_test)\n",
        "image_array_test = np.asarray(image_read_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P3SMwWHhJ02"
      },
      "source": [
        "print(image_array_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPAZpE9mFRn2"
      },
      "source": [
        "print(image_array_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnz164JBhTuD"
      },
      "source": [
        "print(image_array_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHXiG3trHmQO"
      },
      "source": [
        "print(image_array_test)\n",
        "#print(image_array_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOQu4pzxudMe"
      },
      "source": [
        "print(image_array_train.shape,image_array_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBWWx99J3VSK"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y3err9CiByG"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \\\n",
        "    BatchNormalization, concatenate, AveragePooling2D\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XSzTQgoTxYd"
      },
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n",
        "import tensorflow.keras.layers as L\n",
        "\n",
        "\n",
        "input_img = Input(shape=(448, 448, 3))\n",
        "\n",
        "densenet121 = DenseNet121(input_shape=(448, 448,3),\n",
        "                                             weights='imagenet',\n",
        "                                             include_top=False)\n",
        "x1 = densenet121.output\n",
        "x2 = GlobalAveragePooling2D()(x1)\n",
        "#model_concat = concatenate([x2, input_2], axis=-1,name=\"final_feature\")\n",
        "\n",
        "x22 = Dense(512,activation='relu')(x2)\n",
        "x222 = Dense(256,activation='relu',name=\"final_feature\")(x22)\n",
        "x3 = Dropout(.5)(x222)\n",
        "x4 = Dense(3,activation='softmax')(x3)\n",
        "model=Model(inputs=densenet121.input,outputs=x4)\n",
        "\n",
        "\n",
        "\n",
        "densenet121.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LHng-GYxs6p"
      },
      "source": [
        "#Summary of model after adding droput and output layer\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tr4IbFxk77y"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=.0005),loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_04ROdXdHAw"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "es_densenet_121 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=150)\n",
        "mc_densenet_121 = ModelCheckpoint('/content/drive/MyDrive/models_saved/densenet121_256_features.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "hist_densenet121 = model.fit(image_array_train, label_train_cat, validation_data = (image_array_test, label_test_cat), \n",
        "           batch_size=16, epochs=150, verbose=1, callbacks=[es_densenet_121, mc_densenet_121])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkjKvTP4loMO"
      },
      "source": [
        "# load the saved model\n",
        "saved_densenet = load_model('/content/drive/MyDrive/models_saved/densenet121_256_features.h5') \n",
        "# evaluate the model\n",
        "_, train_acc_densenet = saved_densenet.evaluate(image_array_train, label_train_cat, verbose=0)\n",
        "_, test_acc_densenet = saved_densenet.evaluate(image_array_test, label_test_cat, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc_densenet, test_acc_densenet))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7EQ7Jyg2Cju"
      },
      "source": [
        "from sklearn import metrics\n",
        "label_pred = saved_densenet.predict(image_array_test)  \n",
        "#saved_densenet = load_model('best_model_glcm_densenet.h5') \n",
        "\n",
        "\n",
        "pred = []\n",
        "for i in range(len(label_pred)):\n",
        "    pred.append(np.argmax(label_pred[i]))\n",
        "\n",
        "Y_test = np.argmax(label_test_cat, axis=1) \n",
        "\n",
        "#print(metrics.classification_report(Y_test, pred))\n",
        "basic_classification_report=metrics.classification_report(Y_test, pred)\n",
        "print(basic_classification_report)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}